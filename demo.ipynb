{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e283bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip  # ensures that pip is current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676239c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git config --global credential.helper store\n",
    "\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e21b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 07:05:00.475835: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-05 07:05:00.489307: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-05 07:05:00.493492: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 07:05:01.852827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Seed set to 12\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "Encoder model frozen.\n",
      "Applied SMT to 8 linear layers with sparsity 0.9\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 2025-05-05_07-05-04.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/tsun/Doding/MINECAPS/COMETHINT/checkpoints/2025-05-05_07-05-04 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | encoder             | XLMREncoder        | 573 M  | train\n",
      "1 | layerwise_attention | LayerwiseAttention | 26     | train\n",
      "2 | train_corr          | RegressionMetrics  | 0      | train\n",
      "3 | val_corr            | ModuleList         | 0      | train\n",
      "4 | estimator           | FeedForward        | 6.3 M  | train\n",
      "5 | sentloss            | MSELoss            | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "21.0 M    Trainable params\n",
      "558 M     Non-trainable params\n",
      "579 M     Total params\n",
      "2,319.270 Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "441       Modules in eval mode\n",
      "Sanity Checking DataLoader 1: 100%|███████████████| 3/3 [00:00<00:00, 12.48it/s]/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/comet/models/metrics.py:131: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman, _ = stats.spearmanr(preds.tolist(), target.tolist())\n",
      "/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/comet/models/metrics.py:132: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson, _ = stats.pearsonr(preds.tolist(), target.tolist())\n",
      "Loading data/train_ref.csv.                                                     \n",
      "Epoch 0:   2%|▎                   | 77/4200 [00:12<10:52,  6.32it/s, v_num=5-04]\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python ./comet/cli/train_spanish.py \\\n",
    "    --cfg configs/models/cometh_runconfig.yaml \\\n",
    "    --smt_sparsity 0.9 \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --test_file data/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1910b957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 06:57:56.210493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-05 06:57:56.225323: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-05 06:57:56.230003: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 06:57:57.568590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Seed set to 12\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "Encoder model frozen.\n",
      "Applying LoRA to modules: ['encoder.layer.0.attention.self.query', 'encoder.layer.0.attention.self.key', 'encoder.layer.0.attention.self.value', 'encoder.layer.0.attention.output.dense', 'encoder.layer.1.attention.self.query', 'encoder.layer.1.attention.self.key', 'encoder.layer.1.attention.self.value', 'encoder.layer.1.attention.output.dense']\n",
      "LoRA applied successfully\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 2025-05-05_06-58-00.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/tsun/Doding/MINECAPS/COMETHINT/checkpoints/2025-05-05_06-58-00 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | encoder             | XLMREncoder        | 558 M  | train\n",
      "1 | layerwise_attention | LayerwiseAttention | 26     | train\n",
      "2 | train_corr          | RegressionMetrics  | 0      | train\n",
      "3 | val_corr            | ModuleList         | 0      | train\n",
      "4 | estimator           | FeedForward        | 6.3 M  | train\n",
      "5 | sentloss            | MSELoss            | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "6.4 M     Trainable params\n",
      "558 M     Non-trainable params\n",
      "565 M     Total params\n",
      "2,261.074 Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "441       Modules in eval mode\n",
      "Sanity Checking DataLoader 1: 100%|███████████████| 3/3 [00:00<00:00, 13.84it/s]/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/comet/models/metrics.py:131: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman, _ = stats.spearmanr(preds.tolist(), target.tolist())\n",
      "/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/comet/models/metrics.py:132: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson, _ = stats.pearsonr(preds.tolist(), target.tolist())\n",
      "Loading data/train_ref.csv.                                                     \n",
      "Epoch 0:   1%|▏                   | 42/4200 [00:07<11:55,  5.82it/s, v_num=8-00]\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python ./comet/cli/train_polish.py \\\n",
    "    --cfg configs/models/cometh_runconfig.yaml \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --lora_rank 8 \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --test_file data/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377565ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python ./comet/cli/train_italiano.py \\\n",
    "    --cfg ./configs/models/cometh_runconfig.yaml \\\n",
    "    --load_from_checkpoint $model_path \\\n",
    "    --test_file data/test_ref.csv \\\n",
    "    --use_pissa \\\n",
    "    --pissa_rank 8 \\\n",
    "    --pissa_sample_path data/test_ref.csv \\\n",
    "    --warmup_ratio 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2fb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./comet/cli/train_mehico.py \\\n",
    "    --cfg ./configs/models/cometh_runconfig.yaml \\\n",
    "    --load_from_checkpoint $model_path \\\n",
    "    --test_file data/test_ref.csv \\\n",
    "    --use_dora \\\n",
    "    --dora_alpha 16.0 \\\n",
    "    --dora_rank 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
