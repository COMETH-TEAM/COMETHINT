{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e283bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages (25.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip  # ensures that pip is current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676239c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git config --global credential.helper store\n",
    "\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5004ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 06:20:08.615286: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-05 06:20:08.629513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-05 06:20:08.633726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 06:20:08.643765: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-05 06:20:09.483185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac8e957752a45f283ffc067b3d330ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d9af25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tsun/.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/1ad785194e391eebc6c53e2d0776cada8f83179a/checkpoints/model.ckpt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377565ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 06:27:00.677036: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-05 06:27:00.690723: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-05 06:27:00.694845: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-05 06:27:02.028924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Seed set to 12\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/1ad785194e391eebc6c53e2d0776cada8f83179a/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 2025-05-05_06-27-04.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/tsun/Doding/MINECAPS/COMETHINT/checkpoints/2025-05-05_06-27-04 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params | Mode\n",
      "------------------------------------------------------------------\n",
      "0 | encoder             | XLMREncoder        | 558 M  | eval\n",
      "1 | layerwise_attention | LayerwiseAttention | 26     | eval\n",
      "2 | train_corr          | RegressionMetrics  | 0      | eval\n",
      "3 | val_corr            | ModuleList         | 0      | eval\n",
      "4 | estimator           | FeedForward        | 6.3 M  | eval\n",
      "5 | sentloss            | MSELoss            | 0      | eval\n",
      "------------------------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "558 M     Non-trainable params\n",
      "565 M     Total params\n",
      "2,260.550 Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "457       Modules in eval mode\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Sanity Checking DataLoader 0: 100%|███████████████| 3/3 [00:00<00:00,  7.78it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Sanity Checking DataLoader 1: 100%|███████████████| 3/3 [00:00<00:00, 14.98it/s]/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/comet/models/metrics.py:131: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman, _ = stats.spearmanr(preds.tolist(), target.tolist())\n",
      "/home/tsun/.pyenv/versions/VENV/lib/python3.12/site-packages/comet/models/metrics.py:132: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson, _ = stats.pearsonr(preds.tolist(), target.tolist())\n",
      "Loading data/train_ref.csv.                                                     \n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch 0:   2%|▍                   | 95/4200 [00:07<05:14, 13.06it/s, v_num=7-04]\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python ./comet/cli/train_italiano.py \\\n",
    "    --cfg ./configs/models/cometh_runconfig.yaml \\\n",
    "    --load_from_checkpoint $model_path \\\n",
    "    --test_file data/test_ref.csv \\\n",
    "    --use_pissa \\\n",
    "    --pissa_rank 8 \\\n",
    "    --pissa_sample_path data/test_ref.csv \\\n",
    "    --warmup_ratio 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2fb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./comet/cli/train_mehico.py \\\n",
    "    --cfg ./configs/models/cometh_runconfig.yaml \\\n",
    "    --load_from_checkpoint $model_path \\\n",
    "    --test_file data/test_ref.csv \\\n",
    "    --use_dora \\\n",
    "    --dora_alpha 16.0 \\\n",
    "    --dora_rank 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
